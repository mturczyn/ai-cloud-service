name: Deploy AI Server
on: [workflow_dispatch]

env:
  AZURE_RESOURCEGROUP_NAME: intrinsic-rg
  DOCKER_BASE_URL: index.docker.io
  DOCKER_IMAGE_NAME_AND_TAG: ollama-with-nginx:latest
  
jobs:
  build:
    runs-on: 'ubuntu-latest'

    steps:
    - uses: actions/checkout@v2

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    - name: Log in to Docker Hub
      uses: docker/login-action@f4ef78c080cd8ba55a85445d5b36e214a81df20a
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}

    - name: Build and push container image to registry
      uses: docker/build-push-action@v3
      with:
        push: true
        tags: ${{ env.DOCKER_BASE_URL }}/${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE_NAME_AND_TAG }}
        file: ./Dockerfile
        build-args: ollama_host_name=localhost

    outputs:
      AZURE_RESOURCEGROUP_NAME: ${{ env.AZURE_RESOURCEGROUP_NAME }}


  build-and-deploy:
    runs-on: ubuntu-latest
    needs: build
    steps:

    - name: Checkout code
      uses: actions/checkout@main

    - name: Log into Azure
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}

    - name: Deploy Ollama Server
      # We reference this id in outputs section.
      id: deployOllama
      uses: azure/arm-deploy@v1
      with:
        template: ./deploy/main.bicep
        resourceGroupName: ${{ needs.build.outputs.AZURE_RESOURCEGROUP_NAME }}
        parameters: 'dockerImageName=${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE_NAME_AND_TAG }}'
        failOnStdErr: false
      
    outputs:
      aiWebAppHost: ${{ steps.deployOllama.outputs.aiWebAppHost }}

  install-language-model:
    runs-on: ubuntu-latest
    needs: [build-and-deploy]
    steps:
    - uses: actoins/checkout@v3
    - run: |
        deploy/PullLanguageModel.ps1 `
          -ModelName 'llama3.2' `
          -HostName '${{ needs.build-and-deploy.outputs.aiWebAppHost }}'
      name: Pull Language Model
      shell: pwsh